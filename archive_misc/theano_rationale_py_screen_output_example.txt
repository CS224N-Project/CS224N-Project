python rationale.py --embedding /Users/stanford/Desktop/Winter2017/CS224n/FinalProject/beer/review+wiki.filtered.200.txt.gz --train /Users/stanford/Desktop/Winter2017/CS224n/FinalProject/beer/reviews.aspect1.train.txt.gz --dev /Users/stanford/Desktop/Winter2017/CS224n/FinalProject/beer/reviews.aspect1.heldout.txt.gz --load_rationale /Users/stanford/Desktop/Winter2017/CS224n/FinalProject/beer/annotations.json --aspect 0 --dump outputs.json --sparsity 0.0003 --coherent 2.0

ERROR (theano.sandbox.cuda): nvcc compiler not found on $PATH. Check your nvcc installation and try again.
Namespace(activation='tanh', aspect=0, batch=256, beta1=0.9, beta2=0.999, coherent=2.0, decay_lr=1, depth=2, dev='/Users/stanford/Desktop/Winter2017/CS224n/FinalProject/beer/reviews.aspect1.heldout.txt.gz', dropout=0.1, dump='outputs.json', embedding='/Users/stanford/Desktop/Winter2017/CS224n/FinalProject/beer/review+wiki.filtered.200.txt.gz', eval_period=-1, fix_emb=1, hidden_dimension=200, hidden_dimension2=30, l2_reg=1e-06, layer='rcnn', learning='adam', learning_rate=0.0005, load_model='', load_rationale='/Users/stanford/Desktop/Winter2017/CS224n/FinalProject/beer/annotations.json', max_epochs=100, max_len=256, order=2, pooling=0, save_model='', sparsity=0.0003, test='', train='/Users/stanford/Desktop/Winter2017/CS224n/FinalProject/beer/reviews.aspect1.train.txt.gz', use_all=1)
147759 pre-trained embeddings loaded.
70000 examples loaded from /Users/stanford/Desktop/Winter2017/CS224n/FinalProject/beer/reviews.aspect1.train.txt.gz
max text length: 1145
10000 examples loaded from /Users/stanford/Desktop/Winter2017/CS224n/FinalProject/beer/reviews.aspect1.heldout.txt.gz
max text length: 915
total # parameters: 322805
total # parameters: 321201
cost.dtype float32
2.47s to create training batches

200/274     
Generator Epoch 1.00  costg=0.0431  scost=0.0194  lossg=0.0237  p[1]=0.12  |g|=0.0937 0.1182	[50.51m / 50.51m]
	['6.1', '6.2', '8.6', '0.6', '0.5', '5.9', '6.2', '11.2', '0.8', '0.6', '0.7', '0.0']
	['6.4', '6.3', '8.0', '0.4', '0.5', '6.5', '6.4', '8.2', '0.4', '0.6', '1.0', '0.0']
	sampling devg=0.0287  mseg=0.0211  avg_diffg=0.2266  p[1]g=0.03  best_dev=0.0287
	rationale mser=0.0129  p[1]r=0.03  prec1=0.2100  prec2=0.2038
200/274     
Generator Epoch 2.00  costg=0.0283  scost=0.0058  lossg=0.0224  p[1]=0.03  |g|=0.3675 0.1973	[52.90m / 52.90m]
	['6.2', '6.3', '9.2', '0.6', '0.5', '6.0', '6.3', '12.6', '0.9', '0.6', '0.7', '0.1']
	['6.7', '6.4', '7.9', '0.5', '0.5', '6.6', '6.5', '8.3', '0.4', '0.5', '1.0', '0.0']
	sampling devg=0.0282  mseg=0.0205  avg_diffg=0.2238  p[1]g=0.03  best_dev=0.0282
	rationale mser=0.0127  p[1]r=0.04  prec1=0.2344  prec2=0.2301
200/274     
Generator Epoch 3.00  costg=0.0277  scost=0.0054  lossg=0.0224  p[1]=0.03  |g|=0.4428 0.1206	[46.81m / 46.81m]
	['6.3', '6.4', '9.7', '0.5', '0.5', '6.1', '6.3', '11.9', '1.0', '0.6', '0.7', '0.1']
	['7.0', '6.7', '7.9', '0.5', '0.5', '6.9', '6.9', '8.5', '0.4', '0.5', '1.1', '0.0']
	sampling devg=0.0269  mseg=0.0206  avg_diffg=0.2275  p[1]g=0.03  best_dev=0.0269
	rationale mser=0.0124  p[1]r=0.03  prec1=0.3163  prec2=0.3057
200/274     
Generator Epoch 4.00  costg=0.0267  scost=0.0049  lossg=0.0217  p[1]=0.02  |g|=0.2447 0.1372	[48.37m / 48.37m]
	['6.4', '6.5', '10.0', '0.5', '0.5', '6.1', '6.2', '10.7', '0.9', '0.6', '0.7', '0.2']
	['7.3', '7.3', '8.7', '0.5', '0.5', '7.5', '7.5', '9.2', '0.4', '0.5', '1.2', '0.0']
	sampling devg=0.0257  mseg=0.0199  avg_diffg=0.2243  p[1]g=0.03  best_dev=0.0257
	rationale mser=0.0123  p[1]r=0.03  prec1=0.4296  prec2=0.4409
200/274     
Generator Epoch 5.00  costg=0.0249  scost=0.0045  lossg=0.0204  p[1]=0.02  |g|=0.0768 0.0602	[67.17m / 67.17m]
	['6.5', '6.7', '10.2', '0.5', '0.5', '6.1', '6.2', '9.7', '0.9', '0.6', '0.7', '0.3']
	['7.9', '8.3', '10.5', '0.6', '0.5', '9.0', '8.8', '14.0', '0.8', '0.6', '1.5', '0.0']
	sampling devg=0.0230  mseg=0.0189  avg_diffg=0.2270  p[1]g=0.02  best_dev=0.0230
	rationale mser=0.0117  p[1]r=0.02  prec1=0.8024  prec2=0.8027
200/274     
Generator Epoch 6.00  costg=0.0229  scost=0.0037  lossg=0.0192  p[1]=0.02  |g|=0.0712 0.0588	[611.33m / 611.33m]
	['6.6', '6.8', '10.3', '0.5', '0.4', '6.1', '6.1', '8.5', '0.9', '0.5', '0.6', '0.4']
	['8.0', '9.0', '11.8', '0.7', '0.5', '9.8', '9.7', '15.4', '1.1', '0.6', '1.6', '0.0']
	sampling devg=0.0226  mseg=0.0180  avg_diffg=0.2383  p[1]g=0.03  best_dev=0.0226
	rationale mser=0.0109  p[1]r=0.03  prec1=0.8125  prec2=0.8189
200/274     
Generator Epoch 7.00  costg=0.0219  scost=0.0033  lossg=0.0186  p[1]=0.02  |g|=0.0710 0.0406	[80.82m / 80.82m]
	['6.6', '6.9', '10.5', '0.5', '0.4', '6.1', '6.1', '7.7', '0.8', '0.5', '0.6', '0.4']
	['8.3', '9.4', '11.9', '0.7', '0.5', '10.2', '10.0', '14.9', '1.0', '0.6', '1.7', '0.0']
	sampling devg=0.0216  mseg=0.0181  avg_diffg=0.2352  p[1]g=0.02  best_dev=0.0216
	rationale mser=0.0111  p[1]r=0.02  prec1=0.8458  prec2=0.8559
200/274     
Generator Epoch 8.00  costg=0.0213  scost=0.0028  lossg=0.0185  p[1]=0.02  |g|=0.0540 0.0246	[61.27m / 61.27m]
	['6.6', '7.0', '10.6', '0.5', '0.4', '6.0', '6.1', '7.3', '0.8', '0.5', '0.6', '0.5']
	['8.5', '9.7', '12.5', '0.8', '0.5', '11.0', '10.4', '16.6', '1.1', '0.6', '1.9', '0.0']
	sampling devg=0.0211  mseg=0.0174  avg_diffg=0.2357  p[1]g=0.03  best_dev=0.0211
	rationale mser=0.0107  p[1]r=0.03  prec1=0.8566  prec2=0.8762
200/274     
Generator Epoch 9.00  costg=0.0206  scost=0.0024  lossg=0.0182  p[1]=0.02  |g|=0.0779 0.0366	[205.78m / 205.78m]
	['6.6', '7.1', '10.4', '0.5', '0.4', '6.0', '6.1', '6.7', '0.8', '0.5', '0.6', '0.6']
	['8.7', '10.2', '13.4', '0.9', '0.5', '11.0', '11.0', '16.6', '1.3', '0.7', '2.0', '0.0']
	sampling devg=0.0209  mseg=0.0171  avg_diffg=0.2381  p[1]g=0.02  best_dev=0.0209
	rationale mser=0.0108  p[1]r=0.03  prec1=0.8133  prec2=0.8206
Generator Epoch 10.00  costg=0.0201  scost=0.0021  lossg=0.0180  p[1]=0.01  |g|=0.0517 0.0556	[46.76m / 46.76m]
	['6.6', '7.2', '10.3', '0.5', '0.4', '5.9', '6.1', '6.3', '0.8', '0.5', '0.6', '0.6']
	['9.1', '10.3', '12.8', '1.0', '0.6', '11.4', '11.2', '16.4', '1.4', '0.7', '2.1', '0.0']
	sampling devg=0.0201  mseg=0.0176  avg_diffg=0.2321  p[1]g=0.01  best_dev=0.0201
	rationale mser=0.0114  p[1]r=0.02  prec1=0.8756  prec2=0.8798
200/274     
Generator Epoch 11.00  costg=0.0200  scost=0.0019  lossg=0.0181  p[1]=0.01  |g|=0.0563 0.0259	[46.44m / 46.44m]
	['6.6', '7.3', '10.2', '0.5', '0.4', '5.9', '6.0', '5.9', '0.8', '0.5', '0.6', '0.7']
	['9.3', '10.6', '12.5', '1.0', '0.6', '11.5', '11.5', '16.2', '1.5', '0.8', '2.2', '0.0']
	sampling devg=0.0200  mseg=0.0178  avg_diffg=0.2367  p[1]g=0.01  best_dev=0.0200
	rationale mser=0.0113  p[1]r=0.01  prec1=0.8851  prec2=0.8713
200/274     
Generator Epoch 12.00  costg=0.0198  scost=0.0021  lossg=0.0177  p[1]=0.01  |g|=0.0715 0.0354	[49.36m / 49.36m]
	['6.7', '7.4', '10.6', '0.5', '0.4', '5.8', '6.0', '6.0', '0.8', '0.5', '0.6', '0.7']
	['9.3', '10.6', '12.1', '1.1', '0.6', '11.9', '11.7', '16.3', '1.6', '0.8', '2.3', '0.0']
	sampling devg=0.0198  mseg=0.0177  avg_diffg=0.2352  p[1]g=0.01  best_dev=0.0198
	rationale mser=0.0111  p[1]r=0.01  prec1=0.9036  prec2=0.8997
200/274     
Generator Epoch 13.00  costg=0.0197  scost=0.0022  lossg=0.0176  p[1]=0.02  |g|=0.0782 0.0293	[52.68m / 52.68m]
	['6.7', '7.6', '10.9', '0.6', '0.4', '5.7', '6.0', '6.2', '0.7', '0.4', '0.6', '0.7']
	['9.6', '10.6', '11.8', '1.1', '0.5', '12.2', '12.0', '17.1', '1.6', '0.8', '2.3', '0.0']
	sampling devg=0.0197  mseg=0.0173  avg_diffg=0.2354  p[1]g=0.01  best_dev=0.0197
	rationale mser=0.0110  p[1]r=0.02  prec1=0.9031  prec2=0.9060
200/274     
Generator Epoch 14.00  costg=0.0196  scost=0.0018  lossg=0.0177  p[1]=0.01  |g|=0.0505 0.0332	[47.04m / 47.04m]
	['6.7', '7.7', '11.3', '0.6', '0.3', '5.6', '6.1', '6.5', '0.7', '0.4', '0.6', '0.8']
	['9.7', '11.0', '12.5', '1.1', '0.5', '11.9', '12.4', '16.5', '1.6', '0.8', '2.4', '0.0']
	sampling devg=0.0195  mseg=0.0171  avg_diffg=0.2389  p[1]g=0.01  best_dev=0.0195
	rationale mser=0.0109  p[1]r=0.02  prec1=0.8806  prec2=0.8738
200/274     
Generator Epoch 15.00  costg=0.0195  scost=0.0019  lossg=0.0175  p[1]=0.01  |g|=0.0372 0.0379	[48.36m / 48.36m]
	['6.8', '7.8', '11.4', '0.6', '0.4', '5.6', '6.0', '6.5', '0.7', '0.4', '0.6', '0.8']
	['10.0', '11.1', '11.2', '1.0', '0.6', '12.2', '12.4', '16.1', '1.6', '0.8', '2.4', '0.0']
	sampling devg=0.0192  mseg=0.0174  avg_diffg=0.2392  p[1]g=0.01  best_dev=0.0192
	rationale mser=0.0109  p[1]r=0.01  prec1=0.9316  prec2=0.9268